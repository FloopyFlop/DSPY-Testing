{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSPy + StrategyQA with local Ollama (qwen3:30b)\n",
    "\n",
    "This notebook shows a full DSPy pipeline on the StrategyQA dataset using a local Ollama model (`qwen3:30b`).\n",
    "It:\n",
    "- connects DSPy to Ollama,\n",
    "- loads StrategyQA from Hugging Face,\n",
    "- defines a simple Chain-of-Thought module (`question -> rationale, answer`),\n",
    "- measures baseline accuracy,\n",
    "- compiles the module with `BootstrapFewShotWithRandomSearch` to optimize prompts,\n",
    "- measures accuracy again to show the gain from DSPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ecc76ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abm/XVOL/Cornell/CS6784/DSPY-Testing/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If needed, install DSPy and datasets.\n",
    "# You can skip this cell if you already have them.\n",
    "# Note: run this, then restart the kernel before continuing.\n",
    "%pip install -U dspy-ai datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c250d0",
   "metadata": {},
   "source": [
    "## 2. Configure DSPy with local Ollama (`qwen3:30b`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a26746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama is running.\n",
      "✅ DSPy is configured with Ollama: <dspy.clients.lm.LM object at 0x126e9c3e0>\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import requests\n",
    "\n",
    "# Change this if your Ollama server or model name differs.\n",
    "OLLAMA_API_BASE = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"qwen2.5:0.5b\"  # e.g. `ollama pull qwen2.5:0.5b`\n",
    "\n",
    "# Quick sanity check that Ollama is running\n",
    "try:\n",
    "    r = requests.get(f\"{OLLAMA_API_BASE}/api/tags\", timeout=3)\n",
    "    r.raise_for_status()\n",
    "    print(\"✅ Ollama is running.\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Could not reach Ollama. Make sure `ollama serve` is running and the model is pulled.\")\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Configure DSPy to talk to Ollama through its OpenAI-compatible interface.\n",
    "# DSPy uses LiteLLM under the hood, so we treat Ollama as a provider.\n",
    "lm = dspy.LM(\n",
    "    model=f\"ollama_chat/{OLLAMA_MODEL}\",  # chat-style interface for Ollama\n",
    "    api_base=OLLAMA_API_BASE,\n",
    "    api_key=\"\",             # not used for local Ollama\n",
    "    model_type=\"chat\",\n",
    "    max_tokens=512,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm)\n",
    "print(\"✅ DSPy is configured with Ollama:\", lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57996c08",
   "metadata": {},
   "source": [
    "## 3. Load StrategyQA and create DSPy examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ae438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1603\n",
      "Test size: 687\n",
      "Prepared train examples: 128\n",
      "Prepared dev examples: 128\n",
      "Q: Will Chick-fil-A hypothetically refuse to sponsor a Pride parade?\n",
      "A: yes\n",
      "---\n",
      "Q: Would early Eastern Canadian Natives language have use of the letter B?\n",
      "A: no\n",
      "---\n",
      "Q: Does Felix Potvin have a position on a dodgeball team?\n",
      "A: no\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import dspy\n",
    "\n",
    "# We use the ChilleD/StrategyQA variant which has a clean schema:\n",
    "#   question: str\n",
    "#   answer: bool (True/False)\n",
    "#   facts: str (description of reasoning facts)\n",
    "#\n",
    "# Ref: https://huggingface.co/datasets/ChilleD/StrategyQA\n",
    "raw = load_dataset(\"ChilleD/StrategyQA\")\n",
    "\n",
    "train_raw = raw[\"train\"]\n",
    "test_raw = raw[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_raw))\n",
    "print(\"Test size:\", len(test_raw))\n",
    "\n",
    "# For a simple demo, we work on smaller subsets (you can increase these later).\n",
    "random.seed(13)\n",
    "TRAIN_SIZE = 128\n",
    "DEV_SIZE = 128\n",
    "\n",
    "train_indices = list(range(len(train_raw)))\n",
    "random.shuffle(train_indices)\n",
    "train_indices = train_indices[:TRAIN_SIZE]\n",
    "\n",
    "dev_indices = list(range(len(test_raw)))\n",
    "random.shuffle(dev_indices)\n",
    "dev_indices = dev_indices[:DEV_SIZE]\n",
    "\n",
    "# Convert to DSPy Examples with yes/no answers as strings.\n",
    "trainset = []\n",
    "for idx in train_indices:\n",
    "    row = train_raw[int(idx)]\n",
    "    q = row[\"question\"]\n",
    "    a = \"yes\" if bool(row[\"answer\"]) else \"no\"\n",
    "    ex = dspy.Example(question=q, answer=a).with_inputs(\"question\")\n",
    "    trainset.append(ex)\n",
    "\n",
    "devset = []\n",
    "for idx in dev_indices:\n",
    "    row = test_raw[int(idx)]\n",
    "    q = row[\"question\"]\n",
    "    a = \"yes\" if bool(row[\"answer\"]) else \"no\"\n",
    "    ex = dspy.Example(question=q, answer=a).with_inputs(\"question\")\n",
    "    devset.append(ex)\n",
    "\n",
    "print(\"Prepared train examples:\", len(trainset))\n",
    "print(\"Prepared dev examples:\", len(devset))\n",
    "\n",
    "# Peek at a couple of examples\n",
    "for ex in trainset[:3]:\n",
    "    print(\"Q:\", ex.question)\n",
    "    print(\"A:\", ex.answer)\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb29eff",
   "metadata": {},
   "source": [
    "## 4. Define DSPy module and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb5a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Defined StrategyQAModule and metric.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# We give the model room to reason by asking for a rationale and a yes/no answer.\n",
    "# The rationale is not evaluated directly; we only score the final answer.\n",
    "StrategyQASignature = dspy.Signature(\"question -> rationale, answer\")\n",
    "\n",
    "class StrategyQAModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cot = dspy.ChainOfThought(StrategyQASignature)\n",
    "\n",
    "    def forward(self, question: str):\n",
    "        pred = self.cot(question=question)\n",
    "        # Normalize answer a bit in case the LM tries to talk too much.\n",
    "        answer = str(pred.answer).strip().lower()\n",
    "        if answer.startswith(\"yes\"):\n",
    "            answer = \"yes\"\n",
    "        elif answer.startswith(\"no\"):\n",
    "            answer = \"no\"\n",
    "        pred.answer = answer\n",
    "        return pred\n",
    "\n",
    "# Simple exact-match metric on yes/no.\n",
    "# FIXED: Added trace parameter to match DSPy's expected signature\n",
    "def strategyqa_exact_match(gold: dspy.Example, pred: dspy.Prediction, trace=None) -> float:\n",
    "    gold_ans = str(gold.answer).strip().lower()\n",
    "    pred_ans = str(getattr(pred, \"answer\", \"\")).strip().lower()\n",
    "    return 1.0 if gold_ans == pred_ans else 0.0\n",
    "\n",
    "def evaluate_program(program: dspy.Module, dataset, verbose: bool = False) -> float:\n",
    "    scores = []\n",
    "    for i, ex in enumerate(dataset):\n",
    "        pred = program(question=ex.question)\n",
    "        score = strategyqa_exact_match(ex, pred)\n",
    "        scores.append(score)\n",
    "        if verbose and i < 5:\n",
    "            print(f\"Q: {ex.question}\")\n",
    "            print(f\"Gold: {ex.answer}, Pred: {pred.answer}, Score: {score}\")\n",
    "            print(\"Rationale:\", getattr(pred, \"rationale\", \"\"))\n",
    "            print(\"----\")\n",
    "    return sum(scores) / max(len(scores), 1)\n",
    "\n",
    "print(\"✅ Defined StrategyQAModule and metric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a03db4",
   "metadata": {},
   "source": [
    "## 5. Baseline: uncompiled DSPy program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565db089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline program on devset...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m baseline_program = StrategyQAModule()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating baseline program on devset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m baseline_acc = evaluate_program(baseline_program, \u001b[43mtestset\u001b[49m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBaseline dev exact-match accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'testset' is not defined"
     ]
    }
   ],
   "source": [
    "baseline_program = StrategyQAModule()\n",
    "\n",
    "print(\"Evaluating baseline program on devset...\")\n",
    "baseline_acc = evaluate_program(baseline_program, devset, verbose=True)\n",
    "print(f\"Baseline dev exact-match accuracy: {baseline_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f99dd",
   "metadata": {},
   "source": [
    "## 6. Compile with `BootstrapFewShotWithRandomSearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3915d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to bootstrap 12 candidate sets.\n",
      "Compiling StrategyQAModule with DSPy...\n",
      "Average Metric: 32.00 / 128 (25.0%): 100%|██████████| 128/128 [00:00<00:00, 397.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:41:02 INFO dspy.evaluate.evaluate: Average Metric: 32.0 / 128 (25.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 25.0 for seed -3\n",
      "Scores so far: [25.0]\n",
      "Best score so far: 25.0\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:00<00:00, 399.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:41:02 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 48.44 for seed -2\n",
      "Scores so far: [25.0, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/128 [00:00<00:02, 47.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:23<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:41:26 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/128 [00:01<00:40,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:25<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:41:54 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/128 [00:02<00:50,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:25<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:42:21 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/128 [00:00<00:50,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 60.00 / 128 (46.9%): 100%|██████████| 128/128 [00:24<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:42:46 INFO dspy.evaluate.evaluate: Average Metric: 60.0 / 128 (46.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/128 [00:00<00:44,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:24<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:43:12 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/128 [00:01<00:42,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:23<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:43:37 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8/128 [00:02<00:41,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:25<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:44:05 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/128 [00:00<01:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:27<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:44:33 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44, 48.44]\n",
      "Best score so far: 48.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/128 [00:01<00:49,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 63.00 / 128 (49.2%): 100%|██████████| 128/128 [00:26<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:45:01 INFO dspy.evaluate.evaluate: Average Metric: 63.0 / 128 (49.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 49.22 for seed 7\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44, 48.44, 49.22]\n",
      "Best score so far: 49.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/128 [00:01<00:53,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:24<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:45:27 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44, 48.44, 49.22, 48.44]\n",
      "Best score so far: 49.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 7/128 [00:02<00:49,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:25<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:45:55 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44, 48.44, 49.22, 48.44, 48.44]\n",
      "Best score so far: 49.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/128 [00:00<01:01,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:25<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:46:21 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44, 48.44, 49.22, 48.44, 48.44, 48.44]\n",
      "Best score so far: 49.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 7/128 [00:02<00:42,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Average Metric: 62.00 / 128 (48.4%): 100%|██████████| 128/128 [00:25<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/17 18:46:49 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 128 (48.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 48.44, 48.44, 48.44, 48.44, 46.88, 48.44, 48.44, 48.44, 48.44, 49.22, 48.44, 48.44, 48.44, 48.44]\n",
      "Best score so far: 49.22\n",
      "15 candidate programs found.\n",
      "✅ Compilation finished.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(\n",
    "    metric=strategyqa_exact_match,\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=8,\n",
    "    max_rounds=1,\n",
    "    num_candidate_programs=12,\n",
    "    num_threads=4,\n",
    ")\n",
    "\n",
    "print(\"Compiling StrategyQAModule with DSPy...\")\n",
    "compiled_program = teleprompter.compile(\n",
    "    student=StrategyQAModule(),\n",
    "    trainset=trainset,\n",
    "    valset=devset,   # use devset as validation for selecting best prompt config\n",
    ")\n",
    "\n",
    "print(\"✅ Compilation finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate compiled program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating compiled program on devset...\n",
      "Q: Did the Presidency of Bill Clinton conclude with his impeachment?\n",
      "Gold: no, Pred: no, Score: 1.0\n",
      "Rationale: Not supplied for this particular example.\n",
      "----\n",
      "Q: Would a Yeti be likely to have prehensile limbs?\n",
      "Gold: yes, Pred: no, Score: 0.0\n",
      "Rationale: Not supplied for this particular example.\n",
      "----\n",
      "Q: Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?\n",
      "Gold: no, Pred: no, Score: 1.0\n",
      "Rationale: Not supplied for this particular example.\n",
      "----\n",
      "Q: If your electric stove has a glass top, should you use cast iron skillets?\n",
      "Gold: no, Pred: no, Score: 1.0\n",
      "Rationale: Not supplied for this particular example.\n",
      "----\n",
      "Q: Did John Kerry run in the 2010 United Kingdom general election?\n",
      "Gold: no, Pred: no, Score: 1.0\n",
      "Rationale: Not supplied for this particular example.\n",
      "----\n",
      "Compiled dev exact-match accuracy: 0.492\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating compiled program on devset...\")\n",
    "compiled_acc = evaluate_program(compiled_program, devset, verbose=True)\n",
    "print(f\"Compiled dev exact-match accuracy: {compiled_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare and try your own questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline dev accuracy:  0.25\n",
      "Compiled dev accuracy: 0.492\n",
      "\n",
      "Q: Could a modern person call George Washington on the phone?\n",
      "Baseline answer:  no\n",
      "Baseline rationale:\n",
      "The question asks about a modern person calling George Washington on the phone. This implies that we are dealing with an historical or fictional scenario where such a call would be made.\n",
      "\n",
      "Compiled answer: no\n",
      "Compiled rationale:\n",
      "Not supplied for this particular example.\n",
      "\n",
      "Q: Is it possible to walk from New York to London?\n",
      "Baseline answer:  no\n",
      "Baseline rationale:\n",
      "London and New York are located in different time zones, making it impossible for a person to walk between them.\n",
      "\n",
      "Compiled answer: no\n",
      "Compiled rationale:\n",
      "Not supplied for this particular example.\n",
      "\n",
      "Q: Can a human survive without water for more than a week?\n",
      "Baseline answer:  yes\n",
      "Baseline rationale:\n",
      "Water plays a crucial role in maintaining overall bodily functions such as digestion, circulation, and metabolism. Without adequate hydration, the body's ability to perform these functions diminishes, potentially causing serious health problems.\n",
      "\n",
      "Compiled answer: no\n",
      "Compiled rationale:\n",
      "Not supplied for this particular example.\n",
      "\n",
      "Best prompt configuration found by DSPy Teleprompt:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 49.22,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 7,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': -2,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': -1,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 0,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 1,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 3,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 4,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 5,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 6,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 8,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 9,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 10,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 48.44,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 11,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 46.88,\n",
       "  'subscores': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': 2,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))},\n",
       " {'score': 25.0,\n",
       "  'subscores': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0],\n",
       "  'seed': -3,\n",
       "  'program': cot.predict = Predict(StringSignature(question -> reasoning, rationale, answer\n",
       "      instructions='Given the fields `question`, produce the fields `rationale`, `answer`.'\n",
       "      question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "      reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "      rationale = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rationale:', 'desc': '${rationale}'})\n",
       "      answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
       "  ))}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baseline dev accuracy: \", round(baseline_acc, 3))\n",
    "print(\"Compiled dev accuracy:\", round(compiled_acc, 3))\n",
    "\n",
    "# Quick helper to compare baseline vs compiled on custom questions.\n",
    "def ask(question: str):\n",
    "    print(\"\\nQ:\", question)\n",
    "    base_pred = baseline_program(question=question)\n",
    "    comp_pred = compiled_program(question=question)\n",
    "\n",
    "    print(\"Baseline answer: \", base_pred.answer)\n",
    "    print(\"Baseline rationale:\")\n",
    "    print(getattr(base_pred, \"rationale\", \"\"))\n",
    "    print()\n",
    "    print(\"Compiled answer:\", comp_pred.answer)\n",
    "    print(\"Compiled rationale:\")\n",
    "    print(getattr(comp_pred, \"rationale\", \"\"))\n",
    "\n",
    "# Example usage:\n",
    "ask(\"Could a modern person call George Washington on the phone?\")\n",
    "ask(\"Is it possible to walk from New York to London?\")\n",
    "ask(\"Can a human survive without water for more than a week?\")\n",
    "\n",
    "# Output the best prompt configuration found.\n",
    "print(\"\\nBest prompt configuration found by DSPy Teleprompt:\")\n",
    "compiled_program.candidate_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d26456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
